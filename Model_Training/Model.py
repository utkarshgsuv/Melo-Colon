# -*- coding: utf-8 -*-
"""Untitled15.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KupfkLfkZF4d7yhAZk8I64pSCNG57DUF
"""

from google.colab import drive
drive.mount('/content/drive')

!cp "/content/drive/MyDrive/TESS.zip" "/content/"
!cp "/content/drive/MyDrive/RAVDESS.zip" "/content/"
!cp "/content/drive/MyDrive/CREMA-D.zip" "/content/"

import zipfile
import os

# Define paths
dataset_paths = ["/content/TESS.zip", "/content/RAVDESS.zip", "/content/CREMA-D.zip"]
extract_folder = "/content/datasets/"

# Extract all datasets
for path in dataset_paths:
    with zipfile.ZipFile(path, 'r') as zip_ref:
        zip_ref.extractall(extract_folder)

print(f"Datasets extracted successfully{extract_folder}!")

import os

extract_folder = "/content/datasets/"

# Search for .wav files in all subdirectories
audio_files = []
for root, _, files in os.walk(extract_folder):
    for f in files:
        if f.endswith(".wav"):
            audio_files.append(os.path.join(root, f))

print(f"✅ Found {len(audio_files)} audio files.")

!pip install numpy librosa soundfile tensorflow keras matplotlib seaborn

import numpy as np
import librosa
import librosa.display
import soundfile as sf
import os
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, LSTM, Flatten, Dropout, BatchNormalization
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import random

import numpy as np
import librosa
import os
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

import os
import pandas as pd

data_dir = "/content/datasets/"  # Update this with your dataset path
audio_files = []
labels = []

# Define emotion mappings for RAVDESS and CREMA-D
ravdess_emotions = {
    "01": "neutral", "02": "calm", "03": "happy", "04": "sad",
    "05": "angry", "06": "fearful", "07": "disgust", "08": "surprised"
}

cremad_emotions = {
    "NEU": "neutral", "HAP": "happy", "SAD": "sad", "ANG": "angry",
    "FEA": "fearful", "DIS": "disgust"
}

# Walk through dataset directories
for root, _, files in os.walk(data_dir):
    print(f"DEBUG: Found directory -> {root}")  # Debugging

    for f in files:
        if f.endswith(".wav"):
            file_path = os.path.join(root, f)
            label = "unknown"  # Default label

            # ✅ RAVDESS Dataset
            if "RAVDESS" in root or "audio_speech_actors_01-24" in root or "Actor_" in root:
                parts = f.split("-")
                if len(parts) > 2:
                    emotion_code = parts[2].zfill(2)  # Ensure it's a two-digit string
                    label = ravdess_emotions.get(emotion_code, "unknown")

            # ✅ CREMA-D Dataset
            elif "CREMA-D" in root or "AudioWAV" in root:
                parts = f.split("_")
                if len(parts) >= 3:
                    emotion_code = parts[2]
                    label = cremad_emotions.get(emotion_code, "unknown")

            # ✅ TESS Dataset (Extract emotion from filename)
            elif "TESS" in root or "TESS Toronto emotional speech set data" in root:
                if "OAF" in f or "YAF" in f:
                    for emo in ravdess_emotions.values():  # Check against known emotions
                        if emo in f.lower():
                            label = emo
                            break

            # Only add files if they have a known label
            if label != "unknown":
                audio_files.append(file_path)
                labels.append(label)
                print(f"DEBUG: File -> {f}, Emotion -> {label}")  # Debugging

# Verify data consistency
if len(audio_files) != len(labels):
    print(f"❌ Mismatch in number of files and labels!")
    print(f"Files found: {len(audio_files)}, Labels assigned: {len(labels)}")
else:
    print(f"✅ All valid files labeled correctly! Total: {len(audio_files)}")

# Convert to DataFrame
labels_df = pd.DataFrame({"filename": audio_files, "emotion": labels})

# Count occurrences of each emotion
emotion_counts = labels_df["emotion"].value_counts()
print("✅ Final Label Distribution:\n", emotion_counts)

# Save CSV without "unknown" labels
labels_df.to_csv("emotion_labels_filtered.csv", index=False)
print("✅ Labels saved to emotion_labels_filtered.csv (without unknown labels)")

# Standardized emotion mapping
emotion_map = {
    "OAF_Sad": "sad",
    "YAF_sad": "sad",
    "OAF_happy": "happy",
    "YAF_happy": "happy",
    "OAF_angry": "angry",
    "YAF_angry": "angry",
    "OAF_neutral": "neutral",
    "YAF_neutral": "neutral",
    "OAF_Fear": "fearful",
    "YAF_fear": "fearful",
    "OAF_Pleasant_surprise": "surprised",
    "YAF_pleasant_surprised": "surprised",
    "OAF_disgust": "disgust",
    "YAF_disgust": "disgust"
}

# Apply the mapping
labels_df["emotion"] = labels_df["emotion"].replace(emotion_map)

# Check corrected distribution
print("✅ Fixed Label Distribution:\n", labels_df["emotion"].value_counts())

labels = labels_df["emotion"].values  # Extract emotion labels

labels_df.to_csv("/content/drive/MyDrive/emotion_labels.csv", index=False)
print("✅ Labels saved to emotion_labels.csv")

def extract_features(audio_file):
    y, sr = librosa.load(audio_file, sr=22050)

    # Pitch Features
    pitch_values = librosa.yin(y, fmin=50, fmax=300)
    pitch_mean, pitch_std, pitch_range = np.mean(pitch_values), np.std(pitch_values), np.ptp(pitch_values)

    # Intensity Features
    rms_energy = librosa.feature.rms(y=y).flatten()
    intensity_mean, intensity_std, intensity_range = np.mean(rms_energy), np.std(rms_energy), np.ptp(rms_energy)

    # Speech Rate
    duration = librosa.get_duration(y=y, sr=sr)
    peaks= librosa.effects.split(y, top_db=30)
    speech_rate = len(peaks) / duration if duration > 0 else 0

    # Spectral Features
    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))

    # Zero Crossing Rate
    zcr = np.mean(librosa.feature.zero_crossing_rate(y=y))

    # MFCC Features (First 13 Coefficients)
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
    mfccs_mean = np.mean(mfccs, axis=1)

    # Final Feature Vector
    feature_vector = np.hstack([
        pitch_mean, pitch_std, pitch_range,
        intensity_mean, intensity_std, intensity_range,
        speech_rate, spectral_centroid, spectral_rolloff, zcr,
        mfccs_mean
    ])

    return feature_vector

# Load the labels from the CSV file
label_df = pd.read_csv("emotion_labels_filtered.csv")

# Load the labels from the CSV file
label_df = pd.read_csv("emotion_labels_filtered.csv")

# Use 'filename' instead of 'file_name'
file_to_label = dict(zip(label_df['filename'], label_df['emotion']))

print(label_df.columns)  # See actual column names

label_df.columns = label_df.columns.str.strip()  # Remove leading/trailing spaces

features = []
labels = []
import soundfile as sf

def is_valid_audio(audio_path):
    try:
        with sf.SoundFile(audio_path) as f:
            return len(f) > 0  # Check if file has any samples
    except:
        return False  # If reading fails, it's an invalid file


for file in audio_files:
    audio_path = os.path.join("dataset_path", file)
    if os.path.exists(audio_path) and is_valid_audio(audio_path):  # Ensure valid audio
        feature_vector = extract_features(audio_path)
        features.append(feature_vector)
        labels.append(file_to_label[file])

df = pd.DataFrame(features)
df['label'] = labels  # Add emotion labels

X = df.iloc[:, :-1]  # Features
y = df['label']  # Labels

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Check the first few rows of X (features)
print("Features (X) Sample:")
print(X.head())  # Display first 5 rows

# Check the shape of X
print(f"X Shape: {X.shape}")  # Number of rows and columns

# Check the first few values of y (labels)
print("\nLabels (y) Sample:")
print(y.head())  # Display first 5 labels

# Check unique labels in y
print("\nUnique Labels in y:")
print(y.unique())

# Check the distribution of labels

print(df.columns)

print(df.dtypes)

print(df.describe())

!pip install scikit-learn

from sklearn.ensemble import RandomForestClassifier

# Create and train the Random Forest model
rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import joblib

# Save the model
joblib.dump(rf_model, "random_forest_model.pkl")

# Load the model later (when needed)
rf_model_loaded = joblib.load("random_forest_model.pkl")

from sklearn.model_selection import GridSearchCV

# Define parameter grid
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Create GridSearchCV
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1, verbose=2)

# Train the model with the best parameters
grid_search.fit(X_train, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

print("Best Parameters:", grid_search.best_params_)

import librosa
import numpy as np

# Function to extract features from live audio
def extract_features_from_audio(audio_path):
    features = extract_features(audio_path)  # Pass only the file path
    return np.array(features).reshape(1, -1)

# Predict from a new audio file
new_audio = "1001_DFA_DIS_XX.wav"
features = extract_features_from_audio(new_audio)
prediction = model.predict(features)[0]

print("Predicted Emotion:", prediction)

print("Train Accuracy:", accuracy_score(y_train, best_rf_model.predict(X_train)))
print("Test Accuracy:", accuracy_score(y_test, best_rf_model.predict(X_test)))

y_pred = best_rf_model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report
print("Test Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

import joblib
joblib.dump(best_rf_model, "best_random_forest.pkl")
print("Model saved as best_random_forest.pkl")

from google.colab import drive
drive.mount('/content/drive')

import joblib

# Define the save path (inside your Drive)
model_path = "/content/drive/My Drive/best_rf_model.pkl"

# Save the model
joblib.dump(best_rf_model, model_path)

print(f"Model saved at: {model_path}")

import joblib

# Define the save path (inside your Drive)
model_path = "/content/drive/My Drive/rf_model.pkl"

# Save the model
joblib.dump(rf_model, model_path)

print(f"Model saved at: {model_path}")

import joblib

# Load the model
model = joblib.load("best_rf_model.pkl")

# Check if the model is loaded
print(model)

